{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import h5py\n",
    "import cv2\n",
    "import scipy.cluster\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches\n",
    "\n",
    "from vsim_common import load_vocabulary, descriptors_to_bow_vector, load_SIFT_file, \\\n",
    "                        VisualDatabase, SiftColornamesDatabase, AnnVisualDatabase, sift_file_for_image, inside_roi, \\\n",
    "                        filter_roi, label_data_annoy, label_data\n",
    "\n",
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_DIR = '/home/hannes/Datasets/narrative2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "database_data = [\n",
    "                #'db_gridsift_2k.h5'\n",
    "                 #'db_sift_15k.h5',\n",
    "                 #'db_sift_10k.h5',\n",
    "                 #'db_sift_5k.h5',\n",
    "                 #'db_sift_2k.h5',\n",
    "                ]\n",
    "\n",
    "#databases = [VisualDatabase.from_file(db_path, stop_bottom=0.05, stop_top=0.1) for db_path in database_data]\n",
    "#db = MultiVisualDatabase(databases)\n",
    "\n",
    "#db = AnnVisualDatabase.from_file('db_sift_300k.h5', stop_bottom=0.01, stop_top=0.1)\n",
    "#db = AnnVisualDatabase.from_file('db_sift_200k.h5', stop_bottom=0, stop_top=0.1)\n",
    "#db = AnnVisualDatabase.from_file('db_sift_100k.h5', stop_bottom=0, stop_top=0.2)\n",
    "#db = AnnVisualDatabase.from_file('db_sift_200k.h5', stop_top=0.1)\n",
    "#db = VisualDatabase.from_file('db_cname_500.h5', stop_top=0.1)\n",
    "db = SiftColornamesDatabase.from_files('db_sift_10k.h5', 'db_cname_15k.h5', sift_stop_top=0.1, cname_stop_top=0.1)\n",
    "#db = VisualDatabase.from_file('db_sift_15k.h5', stop_top=0.1)\n",
    "\n",
    "#ann_dbs = [AnnVisualDatabase.from_file('db_sift_{:d}k.h5'.format(k), stop_bottom=0, stop_top=0.1) for k in [100, 15]]\n",
    "#db = MultiVisualDatabase(ann_dbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DATASET_DIR, 'labels.txt'), 'r') as f:\n",
    "    label_dict = {}\n",
    "    for line in f.readlines():\n",
    "        filename, *labels = line.split()\n",
    "        label_dict[filename] = labels\n",
    "\n",
    "def top_n_score(matches, n, label='H'):\n",
    "    top_n = []\n",
    "    if n > len(matches):\n",
    "        raise ValueError(\"Selected n={:d} is larger than available matches {:d}\".format(n, len(matches)))\n",
    "        \n",
    "    for i, (fname, score, *_) in enumerate(matches, start=1):\n",
    "        if label in label_dict[fname + '.jpg']:\n",
    "            top_n.append(i)\n",
    "            if len(top_n) == n:\n",
    "                break\n",
    "    return sum(top_n)\n",
    "\n",
    "def top_n_prob(matches, n, label='PE'):\n",
    "    if n > len(matches):\n",
    "        raise ValueError(\"Selected n={:d} is larger than available matches {:d}\".format(n, len(matches)))\n",
    "    num_label_top_n = Counter(label in label_dict[fname + '.jpg'] for fname, score, *_ in matches[:n])[True]\n",
    "    top_n_inlier_rate = num_label_top_n / n\n",
    "    \n",
    "    return top_n_inlier_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_result(matches, n, maxn=None):\n",
    "    print('Top {:d} score: {:d} (theoretical minimum={:d})'.format(n, top_n_score(matches, n), sum(range(n))))\n",
    "    \n",
    "    if maxn is None:\n",
    "        maxn = min(len(matches), len(label_dict))\n",
    "    top_n_chances = np.array([top_n_prob(matches, n) for n in range(1, maxn+1)])\n",
    "    num_inliers = Counter('H' in v for v in label_dict.values())[True]\n",
    "    random_chance = num_inliers / len(label_dict)\n",
    "    print('Top {:d} inlier probability: {:.1f}% (random chance {:.1f}%)'.format(n, 100 * top_n_prob(matches, n), 100*random_chance))\n",
    "    fig, (ax1, ax2) = plt.subplots(2,1, figsize=(12, 7))\n",
    "    ax1.plot(range(1, maxn+1), top_n_chances)\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.axhline(random_chance, color='k')\n",
    "    #plt.plot(range(1, maxn+1), top_n_chances / top_n_chances[-1])\n",
    "    #plt.ylabel('Improvement over pure chance')\n",
    "    #plt.axhline(1.0, color='k')\n",
    "    ax1.axvline(num_inliers, color='r')\n",
    "    ax1.axvline(n, color='g')\n",
    "    ax1.set_xlim(0, min(maxn+1, int(5*n), len(label_dict)))\n",
    "    ax1.set_ylim(0, 1.05)\n",
    "    print(num_inliers)\n",
    "\n",
    "    scores = [score for fname, score, *_ in matches]\n",
    "    ax22 = ax2.twinx()\n",
    "    xdata = np.arange(len(scores))\n",
    "    ax2.plot(xdata, scores, '.')\n",
    "    num_features = []\n",
    "    for i, (fname, score, *_) in enumerate(matches):\n",
    "        if 'H' in label_dict[fname + '.jpg']:\n",
    "            ax2.axvline(i, color='r')\n",
    "        with h5py.File(os.path.join(DATASET_DIR, fname + '.sift.h5'), 'r') as f:\n",
    "            num_features.append(f['descriptors'].shape[0])\n",
    "    ax2.set_xlim(xmin=-1, xmax=min(maxn, len(scores)))\n",
    "    ax22.plot(xdata, num_features, color='g')\n",
    "    ax2.set_ylabel('Distance')\n",
    "    ax22.set_ylabel('#keypoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def min_match(scdb, image, roi, sift_file, cname_file, plot=True):\n",
    "    kwargs = {'method': 'default', 'distance': 'cos', 'use_stop_list': True}\n",
    "    m_sift = dict(scdb.sift_db.query_image(image, roi, sift_file=sift_file, **kwargs))\n",
    "    m_cname = dict(scdb.cname_db.query_image(image, roi, cname_file=cname_file, **kwargs))\n",
    "    \n",
    "    matches = [(key, min(m_sift[key], m_cname[key])) for key in m_sift]\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        sift_scores = sorted(m_sift.values())\n",
    "        cname_scores = sorted(m_cname.values())\n",
    "        min_scores = sorted([s for key, s in matches])\n",
    "        plt.plot(sift_scores, label='SIFT')\n",
    "        plt.plot(cname_scores, label='cname')\n",
    "        plt.plot(min_scores, label='min')\n",
    "        plt.legend()\n",
    "    \n",
    "    return sorted(matches, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kwargs = {'distance': 'cos', 'method': 'default', 'use_stop_list': True}\n",
    "#matches = db.query_image(test_image, roi, sift_file=test_sift_file, cname_file=test_cname_file, **kwargs)\n",
    "#matches = db.sift_db.query_image(test_image, roi, sift_file=test_sift_file, **kwargs)\n",
    "#matches = db.cname_db.query_image(test_image, roi, cname_file=test_cname_file, **kwargs)\n",
    "\n",
    "matches = min_match(db, test_image, roi, test_sift_file, test_cname_file)\n",
    "\n",
    "plot_result(matches, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches_sift = db.sift_db.query_image(test_image, roi, sift_file=test_sift_file, **kwargs)\n",
    "matches_cname = db.cname_db.query_image(test_image, roi, cname_file=test_cname_file, **kwargs)\n",
    "\n",
    "import collections\n",
    "mval = collections.defaultdict(list)\n",
    "for pos, (key, score) in enumerate(matches_sift):\n",
    "    mval[key].append((score, pos))\n",
    "for pos, (key, score) in enumerate(matches_cname):\n",
    "    mval[key].append((score, pos))\n",
    "\n",
    "image_keys = []\n",
    "image_score_sift = []\n",
    "image_pos_sift = []\n",
    "image_score_cname = []\n",
    "image_pos_cname = []\n",
    "key_order = [key for key,_ in matches_sift]\n",
    "for key in key_order:\n",
    "    (ss, si), (cs, ci) = mval[key]\n",
    "    image_keys.append(key)\n",
    "    image_score_sift.append(ss)\n",
    "    image_pos_sift.append(si)\n",
    "    image_score_cname.append(cs)\n",
    "    image_pos_cname.append(ci)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(sorted(image_score_sift), label='SIFT')\n",
    "plt.plot(sorted(image_score_cname), label='cname')\n",
    "plt.plot(sorted(np.minimum(image_score_sift, image_score_cname)))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xdata = np.arange(len(image_keys))\n",
    "plt.figure()\n",
    "plt.plot(xdata, image_score_sift, label='SIFT')\n",
    "plt.plot(xdata, image_score_cname, label='cname')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(xdata, image_pos_sift, label='SIFT')\n",
    "plt.plot(xdata, image_pos_cname, label='cname')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools, time, random\n",
    "\n",
    "def spatial_score_affine(query_keypoints, query_descriptors, query_roi, test_keypoints, test_descriptors, label_func):\n",
    "    # Cut out ROI part only\n",
    "    valid = [i for i, kp in enumerate(query_keypoints) if inside_roi(kp, query_roi)]\n",
    "    query_keypoints = [query_keypoints[i] for i in valid]\n",
    "    query_descriptors = query_descriptors[valid]\n",
    "    \n",
    "    query_labels = label_func(query_descriptors)\n",
    "    test_labels = label_func(test_descriptors)\n",
    "    \n",
    "    stop_list = db.stop_list\n",
    "    \n",
    "    if stop_list is not None:\n",
    "        query_valid = [i for i, l in enumerate(query_labels) if l not in stop_list]\n",
    "        test_valid = [i for i, l in enumerate(test_labels) if l not in stop_list]\n",
    "        \n",
    "        print('Stop list; Query {:d} -> {:d}, Test {:d} -> {:d}'.format(len(query_labels), len(query_valid),\n",
    "                                                                      len(test_labels), len(test_valid)))\n",
    "        \n",
    "        query_keypoints = [kp for i, kp in enumerate(query_keypoints) if i in query_valid]\n",
    "        test_keypoints = [kp for i, kp in enumerate(test_keypoints) if i in test_valid]\n",
    "        query_labels = query_labels[query_valid]\n",
    "        test_labels = test_labels[test_valid]\n",
    "    \n",
    "    query_pts = np.array([kp.pt for kp in query_keypoints], dtype='float32').reshape(-1, 1, 2)\n",
    "    test_pts = np.array([kp.pt for kp in test_keypoints], dtype='float32').reshape(-1, 1, 2)\n",
    "    \n",
    "    putative = [(q, t) for (q, lq), (t, lt) in itertools.product(enumerate(query_labels), enumerate(test_labels)) \n",
    "                        if lq == lt]\n",
    "    \n",
    "    print('{:d} of putative matches with same labels, down from {:d} max'.format(\n",
    "            len(putative), len(query_labels) * len(test_labels)))\n",
    "    \n",
    "    # RANSAC affine\n",
    "    ransac_iterations = 50000\n",
    "    ransac_threshold = 5.0\n",
    "    t0 = time.time()\n",
    "    \n",
    "    best_num_inliers = 0\n",
    "    for _ in range(ransac_iterations):\n",
    "        random.shuffle(putative)\n",
    "        \n",
    "        model_query_idx = [q for q, t in putative[:3]]\n",
    "        model_test_idx = [t for q, t in putative[:3]]\n",
    "        \n",
    "        model_query_pts = query_pts[model_query_idx]\n",
    "        model_test_pts = test_pts[model_test_idx]\n",
    "        \n",
    "        A = cv2.getAffineTransform(model_query_pts, model_test_pts)\n",
    "        \n",
    "        test_query_idx = [q for q, t in putative[3:]]\n",
    "        test_test_idx = [t for q, t in putative[3:]]\n",
    "        \n",
    "        test_query_pts = query_pts[test_query_idx]\n",
    "        test_test_pts = test_pts[test_test_idx]\n",
    "        \n",
    "        test_query_pts_trfm = cv2.transform(test_query_pts, A)\n",
    "        distances = np.linalg.norm(test_query_pts_trfm - test_test_pts, axis=-1).ravel()\n",
    "        \n",
    "        num_inliers = np.count_nonzero(distances < ransac_threshold)\n",
    "        if num_inliers > best_num_inliers:\n",
    "            best_num_inliers = num_inliers\n",
    "    \n",
    "    elapsed = time.time() - t0\n",
    "    #print('RANSAC took {:.2f} seconds ({:.3g} s/iteration)'.format(elapsed, elapsed / ransac_iterations))\n",
    "    #print('{} inliers'.format(best_num_inliers))\n",
    "    return best_num_inliers\n",
    "    \n",
    "\n",
    "def spatial_score_voting(query_keypoints, query_descriptors, query_roi, test_keypoints, test_descriptors, label_func):\n",
    "    # Cut out ROI part only\n",
    "    valid = [i for i, kp in enumerate(query_keypoints) if inside_roi(kp, query_roi)]\n",
    "    query_keypoints = [query_keypoints[i] for i in valid]\n",
    "    query_descriptors = query_descriptors[valid]\n",
    "    \n",
    "    query_labels = label_func(query_descriptors)\n",
    "    test_labels = label_func(test_descriptors)\n",
    "    \n",
    "    stop_list = db.stop_list\n",
    "    \n",
    "    if stop_list is not None:\n",
    "        query_valid = [i for i, l in enumerate(query_labels) if l not in stop_list]\n",
    "        test_valid = [i for i, l in enumerate(test_labels) if l not in stop_list]\n",
    "        \n",
    "        print('Stop list; Query {:d} -> {:d}, Test {:d} -> {:d}'.format(len(query_labels), len(query_valid),\n",
    "                                                                      len(test_labels), len(test_valid)))\n",
    "        \n",
    "        query_keypoints = [kp for i, kp in enumerate(query_keypoints) if i in query_valid]\n",
    "        test_keypoints = [kp for i, kp in enumerate(test_keypoints) if i in test_valid]\n",
    "        query_labels = query_labels[query_valid]\n",
    "        test_labels = test_labels[test_valid]\n",
    "    \n",
    "    query_pts = np.array([kp.pt for kp in query_keypoints], dtype='float32')\n",
    "    test_pts = np.array([kp.pt for kp in test_keypoints], dtype='float32')\n",
    "    \n",
    "    query_kdtree = scipy.spatial.cKDTree(query_pts, leafsize=32)\n",
    "    test_kdtree = scipy.spatial.cKDTree(test_pts, leafsize=32)\n",
    "    \n",
    "    num_close = 10\n",
    "    votes = 0\n",
    "    for kpq, lq in zip(query_keypoints, query_labels):\n",
    "        _, closeq = query_kdtree.query(kpq.pt, num_close)\n",
    "        cq = Counter(query_labels[closeq])\n",
    "        kp_vote = 0\n",
    "        for kpt, lt in zip(test_keypoints, test_labels):            \n",
    "            if lt == lq:\n",
    "                _, closet = test_kdtree.query(kpt.pt, num_close)\n",
    "                ct = Counter(test_labels[closet])\n",
    "                v = sum((cq & ct).values()) # number of valid 1-to-1 assignments\n",
    "                kp_vote = max(v, kp_vote)\n",
    "        votes += kp_vote\n",
    "        \n",
    "    return votes\n",
    "\n",
    "def label_func_annoy(descriptors, index):\n",
    "    labels = np.empty(len(descriptors), dtype='uint')\n",
    "    for i, x in enumerate(descriptors):\n",
    "        l, *_ = index.get_nns_by_vector(x, 1)\n",
    "        labels[i] = l\n",
    "    return labels\n",
    "\n",
    "from vsim_common import descriptors_to_bow_vector\n",
    "\n",
    "query_des, query_kps = load_SIFT_file(test_sift_file)\n",
    "spatial_check_first_n = 30\n",
    "\n",
    "spatial_check = []\n",
    "for fname, score in matches[:spatial_check_first_n]:\n",
    "    db_image_path = os.path.join(DATASET_DIR, fname + '.jpg')\n",
    "    db_sift_file = sift_file_for_image(db_image_path)\n",
    "    test_des, test_kps = load_SIFT_file(db_sift_file)\n",
    "    votes = spatial_score_voting(query_kps, query_des, roi, test_kps, test_des, lambda x, index=db.index: label_func_annoy(x, index))\n",
    "    #votes = spatial_score_affine(query_kps, query_des, roi, test_kps, test_des, lambda x, index=db.index: label_func_annoy(x, index))\n",
    "    spatial_check.append((fname, score, votes))\n",
    "    print(fname, score, votes, label_dict[fname + '.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spatial_check.sort(key=lambda x: x[2], reverse=True)\n",
    "print('Spatially verified\\n---------------------------------------')\n",
    "plot_result(spatial_check, 10)\n",
    "print('Original matches\\n---------------------------------------')\n",
    "plot_result(matches, 10, maxn=len(spatial_check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = np.random.randint(0, 10, size=(3,3))\n",
    "print(tmp)\n",
    "s = set()\n",
    "for x in tmp.ravel():\n",
    "    s.add(x)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = {*'abcd'}\n",
    "s.difference_update({*'xybz'})\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#des_source = test_sift_file\n",
    "des_source = test_cname_file\n",
    "source_db = db.cname_db\n",
    "qdes, qkps = load_SIFT_file(des_source)\n",
    "print('Query image has {} keypoints'.format(len(qkps)), end=' ')\n",
    "qkps, qdes = filter_roi(qkps, qdes, roi)\n",
    "print('filtered down to {}'.format(len(qkps)))\n",
    "try:\n",
    "\n",
    "    qlabelset = set(label_data_annoy(source_db.index, qdes))\n",
    "    print('Used ANN')\n",
    "except AttributeError:\n",
    "    qlabelset = set(label_data(source_db.vocabulary, qdes))\n",
    "    print('Used exact NN')\n",
    "print('Unique labels:', len(qlabelset))\n",
    "qlabelset.difference_update(source_db.stop_list)\n",
    "print('After stoplist:', len(qlabelset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rows, cols = 5, 2\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(12, 5*rows))\n",
    "\n",
    "stop_list = set(source_db.stop_list)\n",
    "for ax, (fname, score) in zip(axes.flatten(), matches):\n",
    "    image_path = os.path.join(DATASET_DIR, fname + '.jpg')\n",
    "    image = plt.imread(image_path)\n",
    "    \n",
    "    #sift_file = sift_file_for_image(image_path)\n",
    "    sift_file = os.path.splitext(image_path)[0] + '.cname.h5'\n",
    "    \n",
    "    if False:\n",
    "        des, kps = load_SIFT_file(sift_file)\n",
    "        try:\n",
    "            labels = label_data_annoy(source_db.index, des)\n",
    "            print('Using ANN')\n",
    "        except AttributeError:\n",
    "            labels = label_data(source_db.vocabulary, des)\n",
    "            print('Using Exact NN')\n",
    "        #valid = {i for i, (kp, l) in enumerate(zip(kps, labels)) if l in qlabelset}\n",
    "        valid_kps = [kp for i, (kp, l) in enumerate(zip(kps, labels)) if l in qlabelset]\n",
    "        invalid_kps = [kp for i, (kp, l) in enumerate(zip(kps, labels)) if not l in qlabelset and l not in stop_list]\n",
    "        print(fname, len(kps), '->', len(valid_kps), ' + ', len(invalid_kps), ' = ', len(valid_kps) + len(invalid_kps))\n",
    "        grey_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        #kp_image = cv2.drawKeypoints(grey_image, kps, None, (255, 0, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        #ax.imshow(kp_image)\n",
    "\n",
    "        ax.imshow(grey_image, interpolation='none', cmap=plt.cm.Greys_r)\n",
    "\n",
    "        for kps, color, alpha in [(invalid_kps, 'y', 0.75), (valid_kps, 'r', 1.0)]:\n",
    "            pos = np.vstack([kp.pt for kp in kps])\n",
    "            ax.scatter(pos[:, 0], pos[:,1], color=color, marker='x', alpha=alpha)\n",
    "    else:\n",
    "        ax.imshow(image, interpolation='none')\n",
    "    with h5py.File(sift_file, 'r') as f:\n",
    "        num_kps = f['descriptors'].shape[0]\n",
    "    ax.set_title(\"{}{} ({:.3f}, {:d})\".format('[HIT] ' if 'PE' in label_dict[fname+'.jpg'] else '', fname, score, num_kps))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "127e6*((6*8)+64) / 1024**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_filename = '/home/hannes/Datasets/narrative2/20161129_094450_000.jpg'\n",
    "#test_filename = '/home/hannes/Datasets/narrative2/20161129_094114_000.jpg'\n",
    "#test_filename = '/home/hannes/Datasets/narrative2/20161129_095828_000.jpg'\n",
    "test_filename = '/home/hannes/Datasets/narrative2/20161129_091416_000.jpg'\n",
    "test_sift_file = os.path.splitext(test_filename)[0] + '.sift.h5'\n",
    "test_cname_file = os.path.splitext(test_filename)[0] + '.cname.h5'\n",
    "test_image = cv2.imread(test_filename)\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))\n",
    "rois = {'20161129_094450_000.jpg': [1515, 1200, 100, 250], # x, y, w, h\n",
    "        '20161129_094114_000.jpg': [1130, 860, 410, 1020],\n",
    "        '20161129_095828_000.jpg': [2197, 10, 185, 305],\n",
    "        '20161129_091416_000.jpg': [1540, 860, 850, 1600]\n",
    "       }\n",
    "roi = rois.get(os.path.split(test_filename)[-1], None)\n",
    "\n",
    "if roi:\n",
    "    rect = matplotlib.patches.Rectangle(roi[:2], roi[2], roi[3], facecolor='none', edgecolor='r')\n",
    "    ax.add_patch(rect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match features in query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_file = test_cname_file\n",
    "des, kps = load_SIFT_file(source_file)\n",
    "query_kps, query_des = filter_roi(kps, des, roi)\n",
    "query_labels = label_data(db.cname_db.vocabulary, query_des)\n",
    "#test_image_gray = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Cut out only ROI patch\n",
    "def move_to_roi(kp, roi):\n",
    "    x, y, w, h = roi\n",
    "    px, py = kp.pt\n",
    "    new_kp = cv2.KeyPoint(px - x, py - y, kp.size)\n",
    "    return new_kp\n",
    "    \n",
    "x, y, w, h = roi\n",
    "test_image_roi = test_image[y:y+h, x:x+w]\n",
    "test_image_roi = cv2.cvtColor(test_image_roi, cv2.COLOR_BGR2RGB)\n",
    "query_kps = [move_to_roi(kp, roi) for kp in query_kps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_key = '20161129_094802_000'\n",
    "db_image_path = os.path.join(DATASET_DIR, db_key + '.jpg')\n",
    "db_image = cv2.imread(db_image_path)\n",
    "db_image = cv2.cvtColor(db_image, cv2.COLOR_BGR2RGB)\n",
    "db_source_file = os.path.join(DATASET_DIR, db_key + '.cname.h5')\n",
    "db_des, db_kps = load_SIFT_file(db_source_file)\n",
    "db_labels = label_data(db.cname_db.vocabulary, db_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_input = 2\n",
    "max_match = 10\n",
    "selected = np.random.choice(len(query_kps), num_input)\n",
    "\n",
    "matches = []\n",
    "for qi in selected:\n",
    "    ql = query_labels[qi]\n",
    "    num_found = 0\n",
    "    for di, dl in enumerate(db_labels):\n",
    "        if dl == ql:\n",
    "            m = cv2.DMatch(qi, di, 100)\n",
    "            matches.append(m)\n",
    "            num_found += 1\n",
    "            if num_found >= max_match:\n",
    "                break\n",
    "\n",
    "match_image = cv2.drawMatches(test_image_roi, query_kps, db_image, db_kps, matches, np.array([]), flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "print(len(matches), 'matches found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(match_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.linalg.norm(query_des[:5], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(query_des[:5], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(sorted(db.cname_db._log_idf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
